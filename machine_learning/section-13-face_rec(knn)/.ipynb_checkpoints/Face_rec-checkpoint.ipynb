{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCv-basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps\n",
    "- read and show video stream , capture images\n",
    "- detect faces and show bounding box (haarcascade)\n",
    "- flatten the largest face image and save in numpy\n",
    "- repeat for multiple people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./\"\n",
    "face_data = []\n",
    "label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id = 0\n",
    "names = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded  pradyumn.npy\n",
      "loaded  suman.npy\n"
     ]
    }
   ],
   "source": [
    "for fx in os.listdir(data_path):\n",
    "    if fx.endswith('.npy'):\n",
    "        print(\"loaded \",fx)\n",
    "        names[class_id] = fx[:-4]\n",
    "        data_item = np.load(data_path+fx)\n",
    "        face_data.append(data_item)\n",
    "        \n",
    "        # create labels for the class\n",
    "        target = class_id*np.ones((data_item.shape[0],))\n",
    "        class_id += 1\n",
    "        label.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_data = np.concatenate(face_data,axis=0)\n",
    "label = np.concatenate(label,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(269, 30000)\n",
      "(269,)\n"
     ]
    }
   ],
   "source": [
    "print(face_data.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## knn classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(X1,X2):\n",
    "    return np.sqrt(np.sum(np.power((X1-X2),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(X,y,Q,k=5):\n",
    "    \"\"\"\n",
    "    x-> (100,2) np array\n",
    "    y-> (100,) np array\n",
    "    x_query-> (1,2) np array\n",
    "    k-> scaler int\n",
    "    fo knn for classifictation\n",
    "    \n",
    "    \"\"\"\n",
    "    val = []\n",
    "    for i in range(X.shape[0]):\n",
    "        d = dist(X[i],Q)\n",
    "        # distance and label\n",
    "        val.append((d,y[i]))\n",
    "        \n",
    "    vals = np.array(sorted(val)[:k])\n",
    "\n",
    "    return int(max(vals[:,-1]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# id of front cam\n",
    "cap = cv2.VideoCapture(0)\n",
    "face_cascade = cv2.CascadeClassifier(\"./haarcascade_frontalface_default.xml\")\n",
    "\n",
    "skip = 0\n",
    "\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    if ret == False:\n",
    "        continue\n",
    "    # 1 scaling factor - parameter specifting how much the image size is reduced at each image scale\n",
    "    # 2 neibhors - number of frames that shoud specify that a face is present at a particular location \n",
    "    # returns tuple of coordinates (x,y,w,h) of all the faces present\n",
    "    faces = face_cascade.detectMultiScale(frame,1.3,7)\n",
    "\n",
    "    # plotting the boundary\n",
    "    # pick the largest face at end first\n",
    "    for (x,y,w,h) in faces:\n",
    "        # extract region of intrest from the frame\n",
    "        offset = 10 # padding\n",
    "        face_Section = frame[y-offset-5:y+h+offset+5,x-offset:x+w+offset]\n",
    "        # resizing\n",
    "        face_Section = cv2.resize(face_Section,(100,100))\n",
    "        # prediction\n",
    "        out = knn(face_data,label,face_Section.flatten())\n",
    "        cv2.putText(frame,names[out],(x,y-10), cv2.FONT_HERSHEY_SIMPLEX,1,(255, 0, 0),2,cv2.LINE_AA)\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,113,223),3)\n",
    "        \n",
    "    cv2.imshow(\"Video Frame\",frame)\n",
    "    \n",
    "    # we get a 32 bit expression & 11111111 -> 8 bit expression which tells us which kye was pressed  \n",
    "    key_pressed = cv2.waitKey(1) & 0xFF\n",
    "    if key_pressed == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
